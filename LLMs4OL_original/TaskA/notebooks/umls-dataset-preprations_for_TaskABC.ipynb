{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dfe2ce9-9cf9-4559-8b0b-64e363c3c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_data = {\n",
    "    \"mrrel\":{\n",
    "        \"cols\":['CUI1', 'AUI1', 'STYPE1', 'REL', 'CUI2', 'AUI2', 'STYPE2', 'RELA', 'RUI', 'SRUI', 'SAB', 'SL', 'RG', 'DIR', 'SUPPRESS', 'CVF'],\n",
    "        \"not-required-cols\": ['STYPE1', 'SL', 'RG', 'DIR', 'SUPPRESS', 'CVF'],\n",
    "        \"path\": \"../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRREL.RRF\"\n",
    "    },\n",
    "    \"mrconso\":{\n",
    "        \"cols\":['CUI', 'LAT', 'TS', 'LUI', 'STT', 'SUI', 'ISPREF', 'AUI', 'SAUI', 'SCUI', 'SDUI', 'SAB', \n",
    "                'TTY', 'CODE', 'STR', 'SRL', 'SUPPRESS', 'CVF'],\n",
    "        \"not-required-cols\": ['TS', 'LUI', 'STT', 'SUI', 'ISPREF','TTY', 'SCUI', 'SDUI', 'CODE', 'SRL', 'SUPPRESS', 'CVF'],\n",
    "        \"path\": \"../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRCONSO.RRF\"\n",
    "    },\n",
    "    \"mrsty\":{\n",
    "        \"cols\":['CUI', 'TUI', 'STN', 'STY','ATUI', 'CVF'],\n",
    "        \"not-required-cols\": ['CVF'],\n",
    "        \"path\": \"../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRSTY.RRF\"\n",
    "    },\n",
    "    \"mrsat\":{\n",
    "        \"cols\":['CUI', 'LUI', 'SUI', 'METAUI', 'STYPE', 'CODE','ATUI', 'SATUI', 'ATN', 'SAB', 'ATV', 'SUPPRESS','CVF'],\n",
    "        \"not-required-cols\": ['SUPPRESS', 'CVF'],\n",
    "        \"path\": \"../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRSAT.RRF\"\n",
    "    }\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505610b9-b2cb-4e98-ba94-b18f8aafb6cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defnitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad53ee6-4646-4865-9cc6-76c1678a14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_print_columns(path, columns_name, not_required_cols, demo):\n",
    "    df_data_dict = []\n",
    "    false_line = 0\n",
    "    with open(path, 'r') as file_obj:\n",
    "        for index_line, line in tqdm(enumerate(file_obj)):\n",
    "            requireds, line_status = {}, True\n",
    "            \n",
    "            for index_column, line_item in enumerate(line.split(\"|\")[:-1]):\n",
    "                if columns_name[index_column] not in not_required_cols:\n",
    "                    requireds[columns_name[index_column]] = line_item\n",
    "                    # if line_item == \"\":\n",
    "                    #     line_status = False\n",
    "            if line_status:    \n",
    "                if demo:\n",
    "                    df_data_dict.append(list(requireds.values()))\n",
    "                    if index_line == 10:\n",
    "                        df = pd.DataFrame(df_data_dict, columns=[column_name \n",
    "                                                                 for column_name in columns_name \n",
    "                                                                 if column_name not in not_required_cols])\n",
    "                        display(df.head(4))\n",
    "                        return df\n",
    "\n",
    "                else:\n",
    "                    yield requireds\n",
    "            else:\n",
    "                false_line += 1\n",
    "    print(\"False lines:\", false_line)\n",
    "\n",
    "def get_generator(data):\n",
    "    dataset = load_print_columns(mr_data[data]['path'], \n",
    "                             mr_data[data]['cols'], \n",
    "                             mr_data[data]['not-required-cols'], \n",
    "                             demo=False)\n",
    "    return dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def make_bar_plot(X, Y, figsize, title):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(X, Y)\n",
    "    ax.set_title(title)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931822a7-df9f-43fe-8d06-e65ec4890af4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. First Glance on MRREL, MRCONSO, and MRSTY files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a402fb7-c3a3-4e9d-a2b1-753caf6a8a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING‌‌ ON‌‌:: MRREL\n",
      "../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRREL.RRF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5589b7d146e545da9389b82b6d6545cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False lines: 0\n",
      "\n",
      "../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRREL.RRF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f702fdd69449958f468d621d2c5b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False lines: 0\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWORKING‌‌ ON‌‌:: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39mload_print_columns(mr_data[data][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      5\u001b[0m                           mr_data[data][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcols\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      6\u001b[0m                           mr_data[data][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot-required-cols\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      7\u001b[0m                           demo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(load_print_columns(mr_data[data][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     10\u001b[0m                               mr_data[data][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcols\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     11\u001b[0m                               mr_data[data][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot-required-cols\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     12\u001b[0m                               demo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in mr_data.keys():\n",
    "    print(f\"WORKING‌‌ ON‌‌:: {data.upper()}\")\n",
    "    \n",
    "    print(*load_print_columns(mr_data[data]['path'], \n",
    "                              mr_data[data]['cols'], \n",
    "                              mr_data[data]['not-required-cols'], \n",
    "                              demo=True))\n",
    "    \n",
    "    print(next(load_print_columns(mr_data[data]['path'], \n",
    "                                  mr_data[data]['cols'], \n",
    "                                  mr_data[data]['not-required-cols'], \n",
    "                                  demo=False)))\n",
    "    \n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0538073-9eef-47c0-993b-931f2fa1e599",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. create UMLS_feb_skiped_bad_lines.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a4d30e-1787-46e4-bfd3-e350074553c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sabs_to_consider = ['NCI', 'SNOMEDCT_US', 'MEDCIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b32f7d-c03b-45e6-9bb3-3390f0283e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting SAB and STRs from MRCONSO-ENG...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360c0403173549caaf8d55d8f3ae3f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRCONSO.RRF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b401edcd3b894f6789ee0e0ba3f89dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False lines: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting SAB and STRs from MRCONSO-ENG...\")\n",
    "sab_names = {}\n",
    "for conso in tqdm(get_generator(data = 'MRCONSO'.lower())):\n",
    "    if conso['LAT'] == 'ENG' and conso['SAB'] in sabs_to_consider:\n",
    "        sab_names[conso['CUI']+\"-\"+conso['AUI']] = f\"{conso['SAB']}@{conso['STR']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "362ec052-12bc-42e7-b1f8-5a830f38e39d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(sab_names\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m], sab_names[\u001b[38;5;28mlist\u001b[39m(sab_names\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "list(sab_names.keys())[0], sab_names[list(sab_names.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1304f81-1090-4af7-acd4-918011b8881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting CONSO-REL rels and ents based on intersections....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62240b5465504a1b8a0e4f6170f6453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../datasets/TaskA/UMLS/raw/umls-2022AB-metathesaurus-full/2022AB/META/MRREL.RRF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dd4addeb0b41678d3c40b3ca252e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False lines: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Getting CONSO-REL rels and ents based on intersections....\")\n",
    "conso_rel_intersection_rels_ent = defaultdict(int)\n",
    "dataset = get_generator(data = 'MRREL'.lower())\n",
    "sep = \"\\t\"\n",
    "for sample in tqdm(dataset):\n",
    "    found = {}\n",
    "    head, tail = False, False\n",
    "    if sab_names.get(sample['CUI1']+\"-\"+sample['AUI1'], \"NA\") != \"NA\":\n",
    "        found['head'] = f\"{sep}\".join(sab_names[sample['CUI1']+\"-\"+sample['AUI1']].split(\"@\"))\n",
    "        head = True\n",
    "    if sab_names.get(sample['CUI2']+\"-\"+sample['AUI2'], \"NA\") != \"NA\":\n",
    "        found['tail'] = f\"{sep}\".join(sab_names[sample['CUI2']+\"-\"+sample['AUI2']].split(\"@\"))\n",
    "        tail = True \n",
    "    if head and tail:\n",
    "        # file.write(f\"{sample['CUI1']}{sep}{sample['CUI2']}{sep}{sample['RELA']}{sep}{found['head']}{sep}{found['tail']}\\n\")\n",
    "        conso_rel_intersection_rels_ent[f\"{sample['CUI1']}{sep}{sample['AUI1']}{sep}{sample['RUI']}{sep}{sample['CUI2']}{sep}{sample['AUI2']}{sep}{sample['RELA']}{sep}{found['head']}{sep}{found['tail']}\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f101758-82cc-49d7-809b-693b17551ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique samples that avaliable in both MRCONSO-ENG and MRREL:0\n",
      "Number of apperances of samples in both MRCONSO-ENG and MRREL:0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of unique samples that avaliable in both MRCONSO-ENG and MRREL:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(conso_rel_intersection_rels_ent)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of apperances of samples in both MRCONSO-ENG and MRREL:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(conso_rel_intersection_rels_ent\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tqdm(conso_rel_intersection_rels_ent\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m      6\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(line)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv'"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique samples that avaliable in both MRCONSO-ENG and MRREL:{len(conso_rel_intersection_rels_ent)}\")\n",
    "print(f\"Number of apperances of samples in both MRCONSO-ENG and MRREL:{sum(conso_rel_intersection_rels_ent.values())}\")\n",
    "\n",
    "with open(\"../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv\", \"a\") as file:\n",
    "    for line in tqdm(conso_rel_intersection_rels_ent.keys()):\n",
    "        file.write(str(line)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2675f9cc-5a7e-4081-a6fd-a5f3ea32b6bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                  names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUI1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUI1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRUI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUI2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUI2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRELA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAB-CUI1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTR-CUI1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAB-CUI2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTR-CUI2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrevious shape of UMLS initial dataset was: 11455094\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew size of UMLS is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../datasets/TaskA/UMLS/processed-3/UMLS_feb.tsv\", sep=\"\\t\", on_bad_lines='skip',\n",
    "                 names=[\"CUI1\", \"AUI1\", \"RUI\", \"CUI2\", \"AUI2\", \"RELA\", \"SAB-CUI1\", \"STR-CUI1\", \"SAB-CUI2\", \"STR-CUI2\"])\n",
    "\n",
    "print(f\"Previous shape of UMLS initial dataset was: 11455094\")\n",
    "print(f\"New size of UMLS is: {df.shape[0]}\")\n",
    "print(f\"Bad lines that skiped:‌ {11455094-df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f53749-4f80-41b4-9f90-99b0d01b3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../datasets/TaskA/UMLS/processed-3/UMLS_feb_skiped_bad_lines.tsv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b73ccc-e9fd-47ed-b946-4cf8f3c42471",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Generate Ontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0345b5c4-fa9c-439d-9f38-d3918531ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ATUI': 'AT17648347',\n",
    "#  'CUI': 'C0000005',\n",
    "#  'STN': 'A1.4.1.2.1.7',\n",
    "#  'STY': 'Amino Acid, Peptide, or Protein',\n",
    "#  'TUI': 'T116'}\n",
    "\n",
    "df = pd.read_csv(\"../../datasets/TaskA/UMLS/processed-3/UMLS_feb_skiped_bad_lines.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31641f1d-3b7b-4dfa-bae0-af5caca1f77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI1</th>\n",
       "      <th>AUI1</th>\n",
       "      <th>RUI</th>\n",
       "      <th>CUI2</th>\n",
       "      <th>AUI2</th>\n",
       "      <th>RELA</th>\n",
       "      <th>SAB-CUI1</th>\n",
       "      <th>STR-CUI1</th>\n",
       "      <th>SAB-CUI2</th>\n",
       "      <th>STR-CUI2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>A22817493</td>\n",
       "      <td>R20277339</td>\n",
       "      <td>C0031610</td>\n",
       "      <td>A2941532</td>\n",
       "      <td>inverse_isa</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Dipalmitoylphosphatidylcholine</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Phosphatidic acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>A22817493</td>\n",
       "      <td>R13958460</td>\n",
       "      <td>C0523614</td>\n",
       "      <td>A3120482</td>\n",
       "      <td>has_component</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Dipalmitoylphosphatidylcholine</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Dipalmitoylphosphatidylcholine measurement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>A22817493</td>\n",
       "      <td>R141817308</td>\n",
       "      <td>C0523614</td>\n",
       "      <td>A3120482</td>\n",
       "      <td>has_measured_component</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Dipalmitoylphosphatidylcholine</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Dipalmitoylphosphatidylcholine measurement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0000039</td>\n",
       "      <td>A22817493</td>\n",
       "      <td>R142021020</td>\n",
       "      <td>C0216971</td>\n",
       "      <td>A3008866</td>\n",
       "      <td>same_as</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Dipalmitoylphosphatidylcholine</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Colfosceril palmitate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0000052</td>\n",
       "      <td>A27769867</td>\n",
       "      <td>R141668442</td>\n",
       "      <td>C0019495</td>\n",
       "      <td>A3493340</td>\n",
       "      <td>inverse_isa</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>1,4-alpha-Glucan branching enzyme</td>\n",
       "      <td>SNOMEDCT_US</td>\n",
       "      <td>Hexosyltransferase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUI1       AUI1         RUI      CUI2      AUI2  \\\n",
       "0  C0000039  A22817493   R20277339  C0031610  A2941532   \n",
       "1  C0000039  A22817493   R13958460  C0523614  A3120482   \n",
       "2  C0000039  A22817493  R141817308  C0523614  A3120482   \n",
       "3  C0000039  A22817493  R142021020  C0216971  A3008866   \n",
       "4  C0000052  A27769867  R141668442  C0019495  A3493340   \n",
       "\n",
       "                     RELA     SAB-CUI1                           STR-CUI1  \\\n",
       "0             inverse_isa  SNOMEDCT_US     Dipalmitoylphosphatidylcholine   \n",
       "1           has_component  SNOMEDCT_US     Dipalmitoylphosphatidylcholine   \n",
       "2  has_measured_component  SNOMEDCT_US     Dipalmitoylphosphatidylcholine   \n",
       "3                 same_as  SNOMEDCT_US     Dipalmitoylphosphatidylcholine   \n",
       "4             inverse_isa  SNOMEDCT_US  1,4-alpha-Glucan branching enzyme   \n",
       "\n",
       "      SAB-CUI2                                    STR-CUI2  \n",
       "0  SNOMEDCT_US                           Phosphatidic acid  \n",
       "1  SNOMEDCT_US  Dipalmitoylphosphatidylcholine measurement  \n",
       "2  SNOMEDCT_US  Dipalmitoylphosphatidylcholine measurement  \n",
       "3  SNOMEDCT_US                       Colfosceril palmitate  \n",
       "4  SNOMEDCT_US                          Hexosyltransferase  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b0b48-e573-489c-a965-7f8742897b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1 NCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bde6841f-766e-453a-a6ff-74a39106a66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07abb356425547f4b55edcb0b9db0217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63848f05f4c4ed78c88fbb7f2261556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False lines: 0\n",
      "\n",
      "Out of 172538 Unique CUIs for 'NCI' we found Entity types for 172538's\n",
      "\n",
      "A few samples from unique_cuis: ['C0796615', 'C0298456', 'C4527089', 'C0458924', 'C0855054']\n",
      "\n",
      "Examples: C0728966: [['T121'], ['A1.4.1.1.1'], ['Pharmacologic Substance']]\n"
     ]
    }
   ],
   "source": [
    "# ['NCI', 'SNOMEDCT_US', 'MEDCIN']\n",
    "sab_to_consider = 'NCI'\n",
    "\n",
    "sab_rel_df = df[df['SAB-CUI1'].isin([sab_to_consider]) & df['SAB-CUI2'].isin([sab_to_consider])].reset_index()\n",
    "sab_ents_list = sab_rel_df['CUI1'].tolist() + sab_rel_df['CUI2'].tolist()\n",
    "sab_ents_dict = {sab:\"OK\" for sab in list(set(sab_ents_list))}\n",
    "\n",
    "entity_type_dict = {}\n",
    "\n",
    "for mrsty in tqdm(get_generator(data = 'MRSTY'.lower())):\n",
    "    if sab_ents_dict.get(mrsty['CUI'], \"NA\") != \"NA\":\n",
    "        if mrsty['CUI'] in entity_type_dict.get(mrsty['CUI'], \"NA\") != \"NA\":\n",
    "            entity_type_dict[mrsty['CUI']][0].append(mrsty['TUI'])\n",
    "            entity_type_dict[mrsty['CUI']][1].append(mrsty['STN'])\n",
    "            entity_type_dict[mrsty['CUI']][2].append(mrsty['STY'])\n",
    "        else:\n",
    "            entity_type_dict[mrsty['CUI']] = [[mrsty['TUI']], [mrsty['STN']], [mrsty['STY']]]\n",
    "\n",
    "print(f\"\\nOut of {len(sab_ents_dict)} Unique CUIs for '{sab_to_consider}' we found Entity types for {len(entity_type_dict)}'s\")\n",
    "\n",
    "print(\"\\nA few samples from unique_cuis:\", list(sab_ents_dict.keys())[:5])\n",
    "\n",
    "print(f\"\\nExamples: {list(sab_ents_dict.keys())[10]}: {entity_type_dict[list(sab_ents_dict.keys())[10]]}\")\n",
    "\n",
    "\n",
    "stn2str, tui2str = {}, {}\n",
    "tui2stn, tuis, stns = {}, [], []\n",
    "\n",
    "for cui, items in entity_type_dict.items():\n",
    "    tui, stn, string = items[0], items[1], items[2]\n",
    "    for item1, item2, item3 in zip(tui, stn, string):\n",
    "        if stn2str.get(item2, \"NA\") != \"NA\":\n",
    "            if stn2str.get(item2) != item3:\n",
    "                print(f\"conflict-stn2str: {item1}, {item2}, {item3} and ==> {stn2str[item2]}\")\n",
    "        else:\n",
    "            stn2str[item2] = item3\n",
    "            \n",
    "        if tui2str.get(item1, \"NA\") != \"NA\":\n",
    "            if tui2str.get(item1) != item3:\n",
    "                print(f\"conflict-tui2str: {item1}, {item2}, {item3} and ==> {tui2str[item1]}\")\n",
    "        else:\n",
    "            tui2str[item1] = item3 \n",
    "            \n",
    "        if tui2stn.get(item1, \"NA\") != \"NA\":\n",
    "            if tui2stn.get(item1) != item2:\n",
    "                print(f\"conflict-tui2stn: {item1}, {item2}, {item3} and ==> {tui2stn[item1]}\")\n",
    "        else:\n",
    "            tui2stn[item1] = item2 \n",
    "        \n",
    "        \n",
    "        \n",
    "        tuis.append(item1)\n",
    "        stns.append(item2)\n",
    "\n",
    "assert len(stn2str) == len(tui2str)\n",
    "assert len(tui2str) == len(tui2stn)\n",
    "assert len(tui2str) == len(set(tuis))\n",
    "assert len(set(tuis)) == len(set(stns))\n",
    "\n",
    "final_json = {\n",
    "    \"SAB\": sab_to_consider,\n",
    "    \"STN2STR\": stn2str,\n",
    "    \"TUI2STR\": tui2str,\n",
    "    \"TUIs\": list(set(tuis)),\n",
    "    \"STNs\": list(set(stns)),\n",
    "    \"TUI2STN\": tui2stn\n",
    "}\n",
    "\n",
    "with open(sab_to_consider+\"_hierarchy.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "     json.dump(final_json, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98ffb7-8946-4304-99a7-6f5886b93f10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 MEDCIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ebbf3cd-f71a-4224-b600-00d212416b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1091748dca74ed09a5f00d402e4de46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f107b67ea08740dd87025dbe39457b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False lines: 0\n",
      "\n",
      "Out of 377587 Unique CUIs for 'MEDCIN' we found Entity types for 377587's\n",
      "\n",
      "A few samples from unique_cuis: ['C2087929', 'C2139321', 'C2182110', 'C2012112', 'C2077859']\n",
      "\n",
      "Examples: C2123362: [['T034'], ['A2.2.1'], ['Laboratory or Test Result']]\n"
     ]
    }
   ],
   "source": [
    "# ['NCI', 'SNOMEDCT_US', 'MEDCIN']\n",
    "sab_to_consider = 'MEDCIN'\n",
    "\n",
    "sab_rel_df = df[df['SAB-CUI1'].isin([sab_to_consider]) & df['SAB-CUI2'].isin([sab_to_consider])].reset_index()\n",
    "sab_ents_list = sab_rel_df['CUI1'].tolist() + sab_rel_df['CUI2'].tolist()\n",
    "sab_ents_dict = {sab:\"OK\" for sab in list(set(sab_ents_list))}\n",
    "\n",
    "entity_type_dict = {}\n",
    "\n",
    "for mrsty in tqdm(get_generator(data = 'MRSTY'.lower())):\n",
    "    if sab_ents_dict.get(mrsty['CUI'], \"NA\") != \"NA\":\n",
    "        if mrsty['CUI'] in entity_type_dict.get(mrsty['CUI'], \"NA\") != \"NA\":\n",
    "            entity_type_dict[mrsty['CUI']][0].append(mrsty['TUI'])\n",
    "            entity_type_dict[mrsty['CUI']][1].append(mrsty['STN'])\n",
    "            entity_type_dict[mrsty['CUI']][2].append(mrsty['STY'])\n",
    "        else:\n",
    "            entity_type_dict[mrsty['CUI']] = [[mrsty['TUI']], [mrsty['STN']], [mrsty['STY']]]\n",
    "\n",
    "print(f\"\\nOut of {len(sab_ents_dict)} Unique CUIs for '{sab_to_consider}' we found Entity types for {len(entity_type_dict)}'s\")\n",
    "\n",
    "print(\"\\nA few samples from unique_cuis:\", list(sab_ents_dict.keys())[:5])\n",
    "\n",
    "print(f\"\\nExamples: {list(sab_ents_dict.keys())[10]}: {entity_type_dict[list(sab_ents_dict.keys())[10]]}\")\n",
    "\n",
    "\n",
    "stn2str, tui2str = {}, {}\n",
    "tui2stn, tuis, stns = {}, [], []\n",
    "\n",
    "for cui, items in entity_type_dict.items():\n",
    "    tui, stn, string = items[0], items[1], items[2]\n",
    "    for item1, item2, item3 in zip(tui, stn, string):\n",
    "        if stn2str.get(item2, \"NA\") != \"NA\":\n",
    "            if stn2str.get(item2) != item3:\n",
    "                print(f\"conflict-stn2str: {item1}, {item2}, {item3} and ==> {stn2str[item2]}\")\n",
    "        else:\n",
    "            stn2str[item2] = item3\n",
    "            \n",
    "        if tui2str.get(item1, \"NA\") != \"NA\":\n",
    "            if tui2str.get(item1) != item3:\n",
    "                print(f\"conflict-tui2str: {item1}, {item2}, {item3} and ==> {tui2str[item1]}\")\n",
    "        else:\n",
    "            tui2str[item1] = item3 \n",
    "            \n",
    "        if tui2stn.get(item1, \"NA\") != \"NA\":\n",
    "            if tui2stn.get(item1) != item2:\n",
    "                print(f\"conflict-tui2stn: {item1}, {item2}, {item3} and ==> {tui2stn[item1]}\")\n",
    "        else:\n",
    "            tui2stn[item1] = item2 \n",
    "        \n",
    "        \n",
    "        \n",
    "        tuis.append(item1)\n",
    "        stns.append(item2)\n",
    "\n",
    "assert len(stn2str) == len(tui2str)\n",
    "assert len(tui2str) == len(tui2stn)\n",
    "assert len(tui2str) == len(set(tuis))\n",
    "assert len(set(tuis)) == len(set(stns))\n",
    "\n",
    "final_json = {\n",
    "    \"SAB\": sab_to_consider,\n",
    "    \"STN2STR\": stn2str,\n",
    "    \"TUI2STR\": tui2str,\n",
    "    \"TUIs\": list(set(tuis)),\n",
    "    \"STNs\": list(set(stns)),\n",
    "    \"TUI2STN\": tui2stn\n",
    "}\n",
    "\n",
    "with open(sab_to_consider+\"_hierarchy.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "     json.dump(final_json, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f45f1-a816-4677-9d68-6d5043de8fde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.3 SNOMEDCT_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5497001-3db3-4e73-8ccd-9e3045ded438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a759ca3d15a542ee9c90ea1b083a6f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b43ecd02bfa4a569b587b3d40c688cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False lines: 0\n",
      "\n",
      "Out of 417172 Unique CUIs for 'SNOMEDCT_US' we found Entity types for 417172's\n",
      "\n",
      "A few samples from unique_cuis: ['C2711921', 'C0228062', 'C0230393', 'C1276816', 'C3204456']\n",
      "\n",
      "Examples: C2960408: [['T060'], ['B1.3.1.2'], ['Diagnostic Procedure']]\n"
     ]
    }
   ],
   "source": [
    "# ['NCI', 'SNOMEDCT_US', 'MEDCIN']\n",
    "sab_to_consider = 'SNOMEDCT_US'\n",
    "\n",
    "sab_rel_df = df[df['SAB-CUI1'].isin([sab_to_consider]) & df['SAB-CUI2'].isin([sab_to_consider])].reset_index()\n",
    "sab_ents_list = sab_rel_df['CUI1'].tolist() + sab_rel_df['CUI2'].tolist()\n",
    "sab_ents_dict = {sab:\"OK\" for sab in list(set(sab_ents_list))}\n",
    "\n",
    "entity_type_dict = {}\n",
    "\n",
    "for mrsty in tqdm(get_generator(data = 'MRSTY'.lower())):\n",
    "    if sab_ents_dict.get(mrsty['CUI'], \"NA\") != \"NA\":\n",
    "        if mrsty['CUI'] in entity_type_dict.get(mrsty['CUI'], \"NA\") != \"NA\":\n",
    "            entity_type_dict[mrsty['CUI']][0].append(mrsty['TUI'])\n",
    "            entity_type_dict[mrsty['CUI']][1].append(mrsty['STN'])\n",
    "            entity_type_dict[mrsty['CUI']][2].append(mrsty['STY'])\n",
    "        else:\n",
    "            entity_type_dict[mrsty['CUI']] = [[mrsty['TUI']], [mrsty['STN']], [mrsty['STY']]]\n",
    "\n",
    "print(f\"\\nOut of {len(sab_ents_dict)} Unique CUIs for '{sab_to_consider}' we found Entity types for {len(entity_type_dict)}'s\")\n",
    "\n",
    "print(\"\\nA few samples from unique_cuis:\", list(sab_ents_dict.keys())[:5])\n",
    "\n",
    "print(f\"\\nExamples: {list(sab_ents_dict.keys())[10]}: {entity_type_dict[list(sab_ents_dict.keys())[10]]}\")\n",
    "\n",
    "\n",
    "stn2str, tui2str = {}, {}\n",
    "tui2stn, tuis, stns = {}, [], []\n",
    "\n",
    "for cui, items in entity_type_dict.items():\n",
    "    tui, stn, string = items[0], items[1], items[2]\n",
    "    for item1, item2, item3 in zip(tui, stn, string):\n",
    "        if stn2str.get(item2, \"NA\") != \"NA\":\n",
    "            if stn2str.get(item2) != item3:\n",
    "                print(f\"conflict-stn2str: {item1}, {item2}, {item3} and ==> {stn2str[item2]}\")\n",
    "        else:\n",
    "            stn2str[item2] = item3\n",
    "            \n",
    "        if tui2str.get(item1, \"NA\") != \"NA\":\n",
    "            if tui2str.get(item1) != item3:\n",
    "                print(f\"conflict-tui2str: {item1}, {item2}, {item3} and ==> {tui2str[item1]}\")\n",
    "        else:\n",
    "            tui2str[item1] = item3 \n",
    "            \n",
    "        if tui2stn.get(item1, \"NA\") != \"NA\":\n",
    "            if tui2stn.get(item1) != item2:\n",
    "                print(f\"conflict-tui2stn: {item1}, {item2}, {item3} and ==> {tui2stn[item1]}\")\n",
    "        else:\n",
    "            tui2stn[item1] = item2 \n",
    "        \n",
    "        \n",
    "        \n",
    "        tuis.append(item1)\n",
    "        stns.append(item2)\n",
    "\n",
    "assert len(stn2str) == len(tui2str)\n",
    "assert len(tui2str) == len(tui2stn)\n",
    "assert len(tui2str) == len(set(tuis))\n",
    "assert len(set(tuis)) == len(set(stns))\n",
    "\n",
    "final_json = {\n",
    "    \"SAB\": sab_to_consider,\n",
    "    \"STN2STR\": stn2str,\n",
    "    \"TUI2STR\": tui2str,\n",
    "    \"TUIs\": list(set(tuis)),\n",
    "    \"STNs\": list(set(stns)),\n",
    "    \"TUI2STN\": tui2stn\n",
    "}\n",
    "\n",
    "with open(sab_to_consider+\"_hierarchy.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "     json.dump(final_json, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e5af3-06f9-48b8-bf69-b5786b775d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
